Cols<-function(vec){cols=rainbow (length (unique (vec )))return(cols[as.numeric (as.factor (vec))])    }
Cols <- function(vec){
cols=rainbow (length (unique (vec )))
return(cols[as.numeric (as.factor (vec))])}
Cols(nci.labs)
nci.labs
as.numeric(as.factor(nci.labs))
as.factor(nci.labs)
dim(nci.data)
pr.out =prcomp (nci.data , scale=TRUE)
dim(pr.out)
dim(pr.out$rotation)
plot(pr.out$x [,1:2], col =Cols(nci .labs), pch =19,     xlab ="Z1",ylab="Z2")
plot(pr.out$x [,1:2], col =Cols(nci .labs), pch =19, xlab ="Z1",ylab="Z2")
plot(pr.out$x[,1:2], col =Cols(nci .labs), pch =19, xlab ="Z1",ylab="Z2")
plot(pr.out$x[,1:2], col =Cols(nci.labs), pch =19, xlab ="Z1",ylab="Z2")
dim(pr.out$rotation)
dim(pr.out$rotation[,1])
dim(pr.out$rotation[,1])
dim(pr.out$rotation[,1:2])
dim(pr.out$x[,1:2])
pr.out$x
plot(pr.out$x[,2:3], col =Cols(nci.labs), pch =19, xlab ="Z1",ylab="Z2")
sd.data=scale(nci.data)
View(sd.data)
data.dist=dist(sd.data)
64*63/2
data.dist[64]
data.dist[65]
data.dist[63]
min(data.dist)
max(data.dist)
dim(pr.out$x)
view(pr.out)
View(pr.out)
View(pr.out$x)
sin(3)*(1-cos(3)^2)
sqrt(126)*sqrt(14)
126*14
126/4
126/6
126/9
6000*.05
4^4
2^25
a <- c(1/2, sqrt(7)/2)
a
norm(a, "2")
library(data.table)
data.table(a = 1:6)
a <- data.table(a = 1:6)
a[99-a]
a_dt <- data.table(a = 1:6)
a_dt[99-a]
99-a_dt[a]
99-a_dt[.(a)]
99-a_dt[get(a), with = F]
99-a_dt[get(a]
99-a_dt[get(a)]
99-a_dt[[a]]
99-a_dt[["a"]]
99-a_dt[["a"]]
(x**2 âˆ’ 2*x + 2)**2
(x**2 - 2*x + 2)**2
(x**2 - 2*x + 2)**2
x <- seq(-50, 50, length.out = 500)
y <- (x**2 - 2*x + 2)**2
y2 <- x**4
plot(x, y, type = "l", col = "red")
plot(x, y2, type = "l", col = "blue")
y2-y
y2-y > 0
y2-y > 0
y
y2
x <- seq(0, 100, length.out = 500)
y <- (x**2 - 2*x + 2)**2
y2 <- x**4
y2 > y
library(plotly)
subplot(
plot_ly(economics, x = date, y = uempmed),
plot_ly(economics, x = date, y = unemploy),
margin = 0.05,
nrows=2
) %>% layout(showlegend = FALSE)
library(plotly)
subplot(
plot_ly(economics, x = date, y = uempmed),
plot_ly(economics, x = date, y = unemploy),
margin = 0.05,
nrows=2
) %>% layout(showlegend = FALSE)
install.packages("plotly")
library(plotly)
subplot(
plot_ly(economics, x = date, y = uempmed),
plot_ly(economics, x = date, y = unemploy),
margin = 0.05,
nrows=2
) %>% layout(showlegend = FALSE)
attach(economics)
View(economics)
dim(economics)
library(plotly)
subplot(
plot_ly(economics, x = date, y = uempmed),
plot_ly(economics, x = date, y = unemploy),
margin = 0.05,
nrows=2
) %>% layout(showlegend = FALSE)
library(plotly)
subplot(
plot_ly(economics, x = date, y = uempmed),
plot_ly(economics, x = date, y = unemploy),
margin = 0.05,
nrows=2
) %>% layout(showlegend = FALSE)
install.packages("slam")
install.packages("clv")
c_0 <- c(1,1,1,2,2,2,5,5,5,5)
c_1 <- c(1,2,2,3,3,3,4,4,4,4)
c_2 <- c(1,1,1,1,1,1,1,1,1,1)
library(slam)
library(clv)
c_0
c_1
c_2
?slam
??slam
confuse_M <-function(c_0, c_1){
n <- length(c_0)
labels_0 <- unique(c_0)
labels_1 <- unique(c_1)
i <- length(labels_0)
j <- length(labels_1)
M <-simple_triplet_zero_matrix(nrow=i, ncol=j)
for(i in 1:i){
i_index <-which(c_0==labels_0[i])
for(j in 1:j){
j_index <-which(c_1==labels_1[j])
m_ij <-length(intersect(i_index, j_index))
if(m_ij > 0){
M[i,j] <- m_ij
}
}
}
print(dim(M))
return(M)
}
f_measure <-function(c_0, c_1){
stopifnot(length(c_0) == length(c_1))
#M <-confuse_M(c_0, c_1)
M <-clv::confusion.matrix(c_0, c_1)
n <- length(c_0)
tab_0 <- table(c_0)
tab_1 <- table(c_1)
k <- length(tab_0)
l <- length(tab_1)
#mat_0 <- replicate(l, matrix(tab_0, ncol=1), simplify = F) # |C_0_i|
#mat_1 <- replicate(k, matrix(tab_1, ncol=1), simplify = F) # |C_1_j|
mat_0 <- matrix(rep(tab_0, l), ncol=l) # |C_0_i|
mat_1 <- matrix(rep(tab_1, k), ncol=k) # |C_1_j|
#(f_num <-2*mat_0*t(mat_1))  # 2|C_0_i||C_0_j|
f_num <- 2*M
f_denom <-mat_0+t(mat_1)  # |C_0_i|+|C_0_j|
f <- f_num/f_denom  # f(C,C')
c_i_max <-apply(f, 1, max) #max_j{f(C_i,C_j')}
F <- (tab_0 %*% c_i_max)/n  # F(C,C')
return(F)
}
VD_measure <-function(c_0, c_1){
n <- length(c_0)
# Get intersection matrix
#M <-confuse_M(c_0, c_1)
M <-clv::confusion.matrix(c_0, c_1)
sum_0 <-sum(apply(M, 1, max))
sum_1 <-sum(apply(M, 2, max))
D <- 2*n - sum_0 - sum_1
return(D)
}
c_0
c_1
c_2
f_measure(c_0, c_1)
stopifnot(length(c_0) == length(c_1))
M <-clv::confusion.matrix(c_0, c_1)
c_0
M
confuse_M(c_0, c_01)
confuse_M(c_0, c_1)
n <- length(c_0)
n
tab_0 <- table(c_0)
tab_1 <- table(c_1)
tab_0
tab_1
mat_0 <- matrix(rep(tab_0, l), ncol=l) # |C_0_i|
mat_1 <- matrix(rep(tab_1, k), ncol=k) # |C_1_j|
k <- length(tab_0)
l <- length(tab_1)
k
l
mat_0 <- matrix(rep(tab_0, l), ncol=l) # |C_0_i|
mat_1 <- matrix(rep(tab_1, k), ncol=k) # |C_1_j|
mat_0
mat_1
rep(tab_1, 1)
rep(tab_1, 2)
tab_1
k
rep(tab_1, k)
matrix(rep(tab_1, k), ncol=k)
f_num <- 2*M
f_denom <-mat_0+t(mat_1)  # |C_0_i|+|C_0_j|
f_num
mat_0
mat_1
2*M
mat_0
t(mat_1)
mat_0
mat_9
mat_0
dim(mat_0)
dim(mat_1)
mat_0 + t(mat_1)
f_num
dim(f_num)
f_num/f_denom
c_1 <- c(1,2,2,3,3,3,4,4,4,4)
c_2 <- c(1,1,1,1,1,1,1,1,1,1)
M <-clv::confusion.matrix(c_1, c_2)
M
mat_1
mat_0
mat_0
mat_1
t(mat_1)
mat_1
t(mat_1)
mat_0
tab_0
tab_1
f_denom
M
c_0 <- c(1,2,2,3,3,3,4,4,4,4)
c_1 <- c(1,1,1,1,1,1,1,1,1,1)
M <-clv::confusion.matrix(c_0, c_1)
M
tab_0 <- table(c_0)
tab_1 <- table(c_1)
k <- length(tab_0)
l <- length(tab_1)
k
l
mat_0 <- matrix(rep(tab_0, l), ncol=l) # |C_0_i|
mat_1 <- matrix(rep(tab_1, k), ncol=k) # |C_1_j|
#(f_num <-2*mat_0*t(mat_1))  # 2|C_0_i||C_0_j|
f_num <- 2*M
f_denom <-mat_0+t(mat_1)  # |C_0_i|+|C_0_j|
mat_0
mat_1
f_denom <-mat_0+t(mat_1)  # |C_0_i|+|C_0_j|
M
f_num <- 2*M
f_denom <-mat_0+t(mat_1)  # |C_0_i|+|C_0_j|
f <- f_num/f_denom  # f(C,C')
f
c_i_max <-apply(f, 1, max) #max_j{f(C_i,C_j')}
c_i_max
F <- (tab_0 %*% c_i_max)/n  # F(C,C')
F
tab_0
F
options
options()
is.double(c_0)
is.double(F)
getwd()
source("~/Desktop/photo_kaggle/setting_wd.R")
getwd()
training_data <- fread("./data/training.csv")
library(data.table)
training_data <- fread("./data/training.csv")
View(training_data)
training_data$name[1]
strsplit(training_data$name[1], " ")
unlist(strsplit(training_data$name[1], " "))
split_words <- function(cell){
words <- unlist(strsplit(cell))
return(words)
}
training_data[, "name":=split_words(get(name))]
split_words(training_data$name[1])
strsplit(training_data$name[4])
strsplit(training_data$name[4], " ")
split_words <- function(cell){
words <- unlist(strsplit(cell, " "))
ifelse(length(words)>0, return(words), return(NA))
}
split_words(training_data$name[4])
split_words(training_data$name[1])
training_data[, "name":=split_words(get(name))]
name <- sapply(training_data$name, split_words)
name[1:100]
name <- unlist(sapply(training_data$name, split_words))
name
name[1:10]
name[1]
unlist(strsplit(training_data$name[1]))
unlist(strsplit(training_data$name[1], " "))
unlist(strsplit(training_data$name[1], " "))
name[1]
name <- apply(training_data$name, split_words)
name <- apply(training_data$name, FUN = split_words)
name <- apply(as.matrix(training_data$name), FUN = split_words)
name <- sapply(training_data$name,split_words)
name[1]
class(name[1])
name <- unlist(sapply(training_data$name,split_words))
name[1]
names(name[1])
split_words <- function(cell){
words <- as.vector(unlist(strsplit(cell, " ")))
ifelse(length(words)>0, return(words), return(NA))
}
name <- unlist(sapply(training_data$name,split_words))
names(name[1])
name[4]
name[3]
name[5]
name[4]
name[1]
names(name[4])
training_data$name[4]
words <- paste(unlist(strsplit(training_data$name[1], " ")))
words
words[1]
words[2]
words <- paste(unlist(strsplit(training_data$name[1:3], " ")))
words
words
split_words <- function(cell){
words <- paste(unlist(strsplit(cell, " ")))
ifelse(cell == "", return(words), return(NA))
}
name <- sapply(training_data$name,split_words)
name[1]
name[2]
name[3]
split_words(name[1])
split_words(training_data$name[1])
training_data$name==""
training_data$name[1==""
training_data$name[1]==""
split_words <- function(cell){
words <- paste(unlist(strsplit(cell, " ")))
ifelse(cell != "", return(words), return(NA))
}
name <- sapply(training_data$name,split_words)
name[1]
name[2]
name[3]
name[4]
class(name)
training_data[, "name":=name]
View(training_data)
sapply(training_data$name, split_words)
unlist(sapply(training_data$name, split_words))
lapply(training_data$name, FUN = function(x){strsplit(x, " ")})
lapply(training_data$name, FUN = function(x){strsplit(x, " ")[[1]]})
unlist(lapply(training_data$name, FUN = function(x){strsplit(x, " ")[[1]]}))
one_data <- training_data["good" == 1,]
one_data <- training_data["good" == 1]
one_data <- training_data[good == 1]
training_data$good[[1]]
training_data$good==1
training_data$good[1]
training_data$good[2]
training_data$good[2][1]
strsplit(training_data$good[2], "\r")
strsplit(training_data$good[2], "\r")[[1]]
as.numeric(strsplit(training_data$good[2], "\r")[[1]])
as.numeric(training_data$good[1])
training_data[, good := as.numeric(get(good))]
training_data[, good := as.numeric(get("good"))]
View(training_data)
one_data <- training_data[good == 1]
zero_data <- training_data[good == 0]
names_1_vocab <- unlist(lapply(one_data$name, FUN = function(x){strsplit(x, " ")[[1]]}))
names_1_vocab
table(names_1_vocab)
length(unique(names_1_vocab))
source("http://www.dbs.ifi.lmu.de/Lehre/MaschLernen/SS2014/Uebung/perceptron.R")
names_1_vocab
table(names_1_vocab)
one_data$name[1]
strsplit(one_data$name[1])[[1]]
strsplit(one_data$name[1], " ")[[1]]
one_data$name
class(one_data$name)
strsplit(one_data$name[1], " ")[[1]]
get_occur_matrix <- function(char_vec, vocab, tf_idf = FALSE){
occur_df <- as.data.frame(matrix(rep(0, length(char_vec)*length(unique(vocab))),
nrow = length(char_vec), ncol = length(unique(vocab))))
colnames(occur_df) <- unique(vocab)
for(i in 1:nrow(occur_df)){
words <- strsplit(char_vec[i], " ")[[1]]
for(w in words){
occur_df[i, w] <- w
}
}
return(occur_df)
}
get_occur_matrix(one_data$name, names_1_vocab)
get_occur_matrix <- function(char_vec, vocab){
occur_df <- as.data.frame(matrix(rep(0, length(char_vec)*length(unique(vocab))),
nrow = length(char_vec), ncol = length(unique(vocab))))
colnames(occur_df) <- unique(vocab)
for(i in 1:nrow(occur_df)){
words <- strsplit(char_vec[i], " ")[[1]]
for(w in words){
occur_df[i, w] <- 1
}
}
return(occur_df)
}
names_1_occur <- get_occur_matrix(one_data$name, names_1_vocab)
names_0_occur <- get_occur_matrix(zero_data$name, names_0_vocab)
description_1_occur <- get_occur_matrix(one_data$description, description_1_vocab)
description_0_occur <- get_occur_matrix(zero_data$description, description_0_vocab)
caption_1_occur <- get_occur_matrix(one_data$caption, caption_1_vocab)
caption_0_occur <- get_occur_matrix(zero_data$caption, caption_0_vocab)
source('~/Desktop/data_import.R')
dim(names_0_occur)
dim(description_0_occur)
dim(description_1_occur)
dim(caption_1_occur)
dim(caption_0_occur)
dim(caption_1_occur)
caption_0_occur <- get_occur_matrix(zero_data$caption, caption_0_vocab)
names_vocab <- unlist(lapply(training$name, FUN = function(x){strsplit(x, " ")[[1]]}))
description_vocab <- unlist(lapply(training_data$description, FUN = function(x){strsplit(x, " ")[[1]]}))
caption_vocab <- unlist(lapply(training_data$caption, FUN = function(x){strsplit(x, " ")[[1]]}))
names_vocab <- unlist(lapply(training_data$name, FUN = function(x){strsplit(x, " ")[[1]]}))
description_vocab <- unlist(lapply(training_data$description, FUN = function(x){strsplit(x, " ")[[1]]}))
caption_vocab <- unlist(lapply(training_data$caption, FUN = function(x){strsplit(x, " ")[[1]]}))
length(caption_vocab)
length(description_vocab)
names_occur <- get_occur_matrix(training_data$name, names_vocab)
dim(training_data)
dim(names_occur)
names(names_occur)
View(names_occur)
library(e1071)
nb = naiveBayes(training_data$name ~ ., data=names_occur)
nb$tables
t <- nb$tables
View(t)
usv <- svd(names_occur)
plot(usv$d, type = "l", lwd = .8)
usv$d
usv$d[1:20]
table(names_vocab)
hist(as.numeric(table(names_vocab)))
hist(as.numeric(table(names_vocab[training_data$good == 1])))
hist(as.numeric(table(names_vocab[training_data$good == 0])))
nb$tables$889
nb$tables$1659
nb$tables$"1659"
nb$tables$[[1659]]
nb$tables[[1659]]
nb$tables[[1659]][1:10]
nb$tables[[1659]][1:100]
nb$tables[[1659]][1:200]
nb$tables[[1659]][1:500]
nb$tables[[1659]][1:5000]
nb$tables[[1659]][1:5000,]
nb$tables[[1659]][1:5000,2]
"10" %in% names_1_vocab
"10" %in% names_0_vocab
components <- usv$v
dim(components)
components_500 <- components[,1:500]
components_2 <- components[,1:2]
dim(components_2)
projected_data <- names_occur%*%components_2
projected_data <- as.matrix(names_occur)%*%components_2
dim(projected_data)
plot(projected_data[,1], projected_data[,2], pch = 16, col = training_data$good, cex = .6)
plot(projected_data[,1], projected_data[,2], pch = 16, col = ifelse(training_data$good==0, "red", "blue"), cex = .6)
components_2 <- components[,2:3]
projected_data <- as.matrix(names_occur)%*%components_2
plot(projected_data[,1], projected_data[,2], pch = 16, col = ifelse(training_data$good==0, "red", "blue"), cex = .6)
order(table(names_vocab))
table(names_occur)
table(names_vocab)
max(table(names_vocab))
which.max(table(names_vocab))
names(table(names_vocab))[1237]
length(names_vocab)
sum(names_vocab=="293")
as.numeric(table(names_vocab))
sum(as.numeric(table(names_vocab)) >= 1000)
sum(as.numeric(table(description_vocab)) >= 1000)
sum(as.numeric(table(caption_vocab)) >= 1000)
description_occur <- get_occur_matrix(training_data$description, description_vocab)
caption_occur <- get_occur_matrix(training_data$name, caption_vocab)
dim(caption_occur)
dim(description_vocab)
dim(description_occur)
